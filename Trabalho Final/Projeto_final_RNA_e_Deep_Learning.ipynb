{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNA e Deep Learning - Projeto final\n",
        "### Engenharia e Análise de Dados (2025.1)\n",
        "\n",
        "Marcel Pontes &emsp; &emsp;(mfnp2@cesar.school)\n",
        "\n",
        "\n",
        "Rice Image Dataset:\n",
        "https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset/data\n"
      ],
      "metadata": {
        "id": "9O6btB6iKUqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregamento do dateset"
      ],
      "metadata": {
        "id": "c7wRn2pcMzEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehb1_u2tKDWH",
        "outputId": "dcf2e9f3-33aa-42cf-c40e-b4a4f35121f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/muratkokludataset/rice-image-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219M/219M [00:03<00:00, 72.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/muratkokludataset/rice-image-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muratkokludataset/rice-image-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "REDUCED_HEIGHT = 32\n",
        "REDUCED_WIDTH = 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((REDUCED_HEIGHT, REDUCED_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "image_dataset = datasets.ImageFolder(\n",
        "    root=f\"{path}/Rice_Image_Dataset/\",\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "xExf9YDYPRul"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "data_loader_kwargs = {\"shuffle\": True, \"num_workers\": 2, \"batch_size\":32}\n",
        "if use_cuda:\n",
        "  cuda_kwargs = {\n",
        "      \"pin_memory\": True,\n",
        "  }\n",
        "  data_loader_kwargs.update(cuda_kwargs)\n",
        "\n",
        "dataloader = DataLoader(image_dataset, **data_loader_kwargs)"
      ],
      "metadata": {
        "id": "BQqynJqxwQ1C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in dataloader:\n",
        "  print(\"Shape das imagens do batch: \", images.shape)\n",
        "  print(\"Labels:\", labels)\n",
        "  break  # parar depois de um batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bFJOtuD_6iIS",
        "outputId": "afb00f04-d1bd-4492-e750-885a08fed77c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape das imagens do batch:  torch.Size([32, 3, 32, 32])\n",
            "Labels: tensor([0, 0, 2, 2, 1, 4, 4, 2, 3, 2, 4, 1, 3, 1, 4, 3, 0, 2, 3, 3, 2, 4, 2, 4,\n",
            "        4, 1, 2, 0, 2, 0, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do modelo de rede"
      ],
      "metadata": {
        "id": "MzwxVIp3Aglr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dense(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "input_size = 32 * 32 * 3  # height x width x channels\n",
        "\n",
        "model = NeuralNet(input_size, 5)"
      ],
      "metadata": {
        "id": "RNg3zzjN9vL2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento do modelo"
      ],
      "metadata": {
        "id": "J4hvmu3GPN3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "qAZ5pkeulwXC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Criação do objeto de treinamento"
      ],
      "metadata": {
        "id": "aCNMmnM-Pckr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader: DataLoader, model: nn.Module, optimizer_obj, runtime_device, epoch: int):\n",
        "  model.train()\n",
        "  batch_size_sum = 0\n",
        "  for batch_idx, (data, target) in enumerate(data_loader):\n",
        "    data, target = data.to(runtime_device), target.to(runtime_device)\n",
        "\n",
        "    optimizer_obj.zero_grad()\n",
        "    output = model(data)\n",
        "\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer_obj.step()\n",
        "\n",
        "    batch_size_sum += len(data)\n",
        "    if (batch_idx + 1) % 293 == 0:\n",
        "      print(f\"Epoch: {epoch+1} [{batch_size_sum}/{len(data_loader.dataset)}\" \\\n",
        "            f\"\\tLoss: {loss.item():.4f}]\")\n"
      ],
      "metadata": {
        "id": "Q4qQdszAPgpB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "model = NeuralNet(input_size, 5).to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train(dataloader, model, optimizer, device, epoch)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A4gPvjFvIFg",
        "outputId": "4f134b5a-5210-42a5-e187-88ab0ee22ecc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 [9376/75000\tLoss: 1.6822]\n",
            "Epoch: 1 [18752/75000\tLoss: 1.6717]\n",
            "Epoch: 1 [28128/75000\tLoss: 1.6753]\n",
            "Epoch: 1 [37504/75000\tLoss: 1.6575]\n",
            "Epoch: 1 [46880/75000\tLoss: 1.6980]\n",
            "Epoch: 1 [56256/75000\tLoss: 1.6622]\n",
            "Epoch: 1 [65632/75000\tLoss: 1.6290]\n",
            "Epoch: 1 [75000/75000\tLoss: 1.6367]\n",
            "\n",
            "Epoch: 2 [9376/75000\tLoss: 1.6540]\n",
            "Epoch: 2 [18752/75000\tLoss: 1.6377]\n",
            "Epoch: 2 [28128/75000\tLoss: 1.6174]\n",
            "Epoch: 2 [37504/75000\tLoss: 1.6275]\n",
            "Epoch: 2 [46880/75000\tLoss: 1.6616]\n",
            "Epoch: 2 [56256/75000\tLoss: 1.6447]\n",
            "Epoch: 2 [65632/75000\tLoss: 1.6478]\n",
            "Epoch: 2 [75000/75000\tLoss: 1.6309]\n",
            "\n",
            "Epoch: 3 [9376/75000\tLoss: 1.6143]\n",
            "Epoch: 3 [18752/75000\tLoss: 1.6034]\n",
            "Epoch: 3 [28128/75000\tLoss: 1.5689]\n",
            "Epoch: 3 [37504/75000\tLoss: 1.6698]\n",
            "Epoch: 3 [46880/75000\tLoss: 1.6571]\n",
            "Epoch: 3 [56256/75000\tLoss: 1.6741]\n",
            "Epoch: 3 [65632/75000\tLoss: 1.6454]\n",
            "Epoch: 3 [75000/75000\tLoss: 1.5947]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação"
      ],
      "metadata": {
        "id": "ANi0YnGOvGGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "for data, target in dataloader:\n",
        "  data, target = data.to(device), target.to(device)\n",
        "  prediction = model(data)\n",
        "  pred = prediction.argmax(dim=1, keepdim=True)\n",
        "  correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "print(\"A acurácia de classificação com todos os dados ao final do treinamento\")\n",
        "print(\"Accuracy: \", 100*correct/len(dataloader.dataset) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hzZGmlKUNbA",
        "outputId": "5d18c347-0b40-44e9-8535-62aa6610cc35"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A acurácia de classificação com todos os dados ao final do treinamento\n",
            "Accuracy:  15.994666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão"
      ],
      "metadata": {
        "id": "FPWAlnH6OWcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apesar das diversas tentativas de trocas de otimizador da função de perda, do valor de _learning rate_ e incluindo até mesmo uma redução de dimensionalidade do dataset, de forma a se ter uma rede neural menos pesada, o modelo treinado teve extrema dificuldade de se ajustar às imagens do dataset, de forma que, com uma acurácia de 16% e uma perda que não se reduzia com o passar das épocas de treinamento, foi observado um underfit.\n",
        "\n",
        "Ao pesquisar alternativas para melhorar a classificação dos dados, foi sugerida a redução da resolução das imagens. Logo, aplicou-se um `transforms.Resize` para dimensões de 32 x 32 saindo das 250 x 250 originais no processo de carregamento do dataset e consequentemente, a quantidade de nós de entrada do dataset também foi reduzida para refletir a mudança.\n",
        "\n",
        "Uma solução frequentemente comum para lidar com problemas de convergência é a variação do _learning rate_ do modelo treinado. No entanto, essa opção também se mostrou infetiva.\n",
        "\n",
        "Além de uma longa verificação das imagens de entrada e do seu processo de carregamento, experimentou-se a minimização do custo com os algoritmos de Gradiente Descendente Estocástico (SGD) e de Adaptive Movement Estimation (Adam) e três de suas variações. Porém, o resultado desejado não foi atingido.\n",
        "\n",
        "Apesar da não convergência, o estudo foi interessante no entendimento das etapas de criação e arquitetura de uma rede neural para resolução de um desafio de classificação de imagens de grandes proporções. A estratégia adotada de criar o modelo com base em conhecimento passados e das aulas da respectiva disciplina além de pesquisas online proporcionaram uma vantajosa experiência de aprendizado.\n",
        "\n",
        "\n",
        "<br>\n",
        "_Obs.: O número de épocas de treinamento foi mantido baixo para que não fosse gasto muito tempo nas tentativas de otimização além de estar sendo verificado que as iterações já não estavam contribuindo para uma melhora do desempenho._\n",
        "\n"
      ],
      "metadata": {
        "id": "HyHEHf22OmLL"
      }
    }
  ]
}